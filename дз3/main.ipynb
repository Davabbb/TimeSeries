{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание:\n",
    "* [Стационарность](#stacionary)\n",
    "* [Преобразование Бокса-Кокса](#boxcox)\n",
    "* [Модели для предсказания значений временного ряда](#predict)\n",
    "* [Метрики точности прогноза](#metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T15:41:30.568690Z",
     "start_time": "2023-10-19T15:41:30.349074Z"
    }
   },
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.tsa.api as smt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рутина с датасетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T15:41:31.018229Z",
     "start_time": "2023-10-19T15:41:30.572670Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Users/david/TimeSeries/data/Annual precipitation in inches entire great Lakes 19001986.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tsdf_c \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mUsers/david/TimeSeries/data/Annual precipitation in inches entire great Lakes 19001986.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# неподходящий формат данных приводим к тому, с которым Pandas может работать\u001B[39;00m\n\u001B[1;32m      3\u001B[0m tsdf_c[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(tsdf_c[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/TimeSeries/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    945\u001B[0m )\n\u001B[1;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/TimeSeries/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/TimeSeries/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/TimeSeries/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/TimeSeries/venv/lib/python3.9/site-packages/pandas/io/common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'Users/david/TimeSeries/data/Annual precipitation in inches entire great Lakes 19001986.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "tsdf_c = pd.read_csv('Users/david/TimeSeries/data/Annual precipitation in inches entire great Lakes 19001986.csv')\n",
    "# неподходящий формат данных приводим к тому, с которым Pandas может работать\n",
    "tsdf_c['x'] = pd.to_datetime(tsdf_c['x'])\n",
    "# также устанавливаем индекс и сортируем\n",
    "df = tsdf_c.set_index('Time').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисовываем временной ряд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[\"Passengers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стационарный процесс  <a class=\"anchor\" id=\"stacionary\"></a>\n",
    "\n",
    "Стационарный процесс - это случайный процесс, безусловное совместное распределение вероятностей которого не изменяется при сдвиге во времени. Следовательно, такие параметры, как среднее значение и дисперсия, также не меняются со временем, поэтому стационарные временные ряды легче прогнозировать.\n",
    "\n",
    "Есть несколько способов установить, является ли временной ряд стационарным или нет, наиболее распространенными являются старая добрая визуализация, просмотр автокорреляции и выполнение статистических тестов.\n",
    "\n",
    "Наиболее распространенным тестом является тест Дики-Фуллера (также называемый тест ADF), где нулевая гипотеза состоит в том, что временной ряд имеет единичный корень, другими словами, временной ряд не является стационарным.\n",
    "\n",
    "Мы проверим, можно ли отвергнуть нулевую гипотезу, сравнив значение p с выбранным порогом (α), чтобы, если значение p меньше, мы могли отклонить нулевую гипотезу и предположить, что временной ряд с уверенностью является стационарным. уровень 1-α (технически мы просто не можем сказать, что это не так)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Временной ряд имеет единичный корень, или порядок интеграции один, если его первые разности образуют стационарный ряд. Это условие записывается как\n",
    "$y_t\\thicksim I(1)$ если ряд первых разностей $\\triangle y_t=y_t-y_{t-1}$ является стационарным $\\triangle y_t\\thicksim I(0)$.\n",
    "\n",
    "При помощи этого теста проверяют значение коэффициента $a$ в  авторегрессионном уравнении первого порядка AR(1)\n",
    "$y_t=a\\cdot y_{t-1}+\\varepsilon_t,$\n",
    "где $y_t$ — временной ряд, а $\\varepsilon$— ошибка.\n",
    "\n",
    "Если $a=1$, то процесс имеет единичный корень, в этом случае ряд $y_t$ не стационарен, является интегрированным временным рядом первого порядка $I(1)$. Если $|a|<1$, то ряд стационарный $I(0)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем функцию, описывающую тест Дики-Фуллера\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всю теорию, описанную выше, реализуем с помощью statsmodels для проверки\n",
    "# временного ряда перевозок на стационарность\n",
    "\n",
    "alpha = 0.05\n",
    "name = \"Пассажиры\"\n",
    "\n",
    "# определяем временной ряд отдельной переменной\n",
    "ts = df[\"Passengers\"]\n",
    "\n",
    "print(f'Тест Дики-Фуллера ряда {name} :')\n",
    "# определяем результат значения теста из библиотеки с учетом\n",
    "dftest = adfuller(ts, autolag='AIC')\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "print(dfoutput)\n",
    "\n",
    "if dfoutput[\"p-value\"] < alpha:\n",
    "    print(f\"Значение p меньше {alpha * 100}%. Ряд стационарный.\")\n",
    "else:\n",
    "    print(f\"Значение p больше {alpha*100}%. Ряд не стационарный.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь попробуем осуществить дифференцирование. Перед этим опять попробуем декомпозицию ряда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем функцию seasonal_decompose из statsmodels\n",
    "# (то есть осуществляем декомпозицию сигнала/временного ряда)\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# задаем размер графика\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 11, 9\n",
    "\n",
    "\n",
    "# применяем функцию к данным о перевозках\n",
    "decompose = seasonal_decompose(tsdf_c[\"x\"],\n",
    "                               period=6)\n",
    "decompose.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим два временных ряда на основе имеющегося, только без тренда и сезонности.\n",
    "\n",
    "Удаляем тренд согласно формуле: $y' = y_t - y_{t-1}$;\n",
    "\n",
    "Удаляем сезонность согласно формуле: $y' = y_t - y_{t-s}$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nottrend = []\n",
    "s = 6\n",
    "notseason = []\n",
    "\n",
    "# выборка без тренда\n",
    "for i in range(1, len(df[\"x\"])):\n",
    "   nottrend.append(df[\"x\"][i] - df[\"x\"][i-1])\n",
    "\n",
    "# выборка без сезонности\n",
    "for i in range(s, len(df[\"x\"])):\n",
    "   notseason.append(df[\"x\"][i] - df[\"x\"][i-s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отрисовываем временной ряд без тренда\n",
    "plt.plot(nottrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проведем тест Дики-Фуллера на временном ряде без тренда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "name = \"Пассажиры без тренда\"\n",
    " \n",
    "ts = nottrend\n",
    "\n",
    "print(f'Тест Дики-Фуллера ряда {name} :')\n",
    "dftest = adfuller(ts, autolag='AIC')\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "print(dfoutput)\n",
    "\n",
    "if dfoutput[\"p-value\"] < alpha:\n",
    "    print(f\"Значение p меньше {alpha * 100}%. Ряд стационарный.\")\n",
    "else:\n",
    "    print(f\"Значение p больше {alpha*100}%. Ряд не стационарный.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отрисовываем временной ряд без сезонности\n",
    "plt.plot(notseason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичным образом проведем тест Дики-Фуллера на временном ряде без сезонности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "name = \"x без сезона\"\n",
    " \n",
    "ts = notseason\n",
    "\n",
    "print(f'Тест Дики-Фуллера ряда {name} :')\n",
    "dftest = adfuller(ts, autolag='AIC')\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "print(dfoutput)\n",
    "\n",
    "if dfoutput[\"p-value\"] < alpha:\n",
    "    print(f\"Значение p меньше {alpha * 100}%. Ряд стационарный.\")\n",
    "else:\n",
    "    print(f\"Значение p больше {alpha*100}%. Ряд не стационарный.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование Бокса-Кокса <a class=\"anchor\" id=\"boxcox\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование Бокса-Кокса\n",
    "from scipy.stats import boxcox \n",
    "\n",
    "# вызываем функцию преобразования, которая выдает преобразованные данные и\n",
    "# лучший параметр лямбда, который обеспечивает близость к нормальному\n",
    "# распределению\n",
    "transformed_data, best_lambda = boxcox(df[\"x\"])\n",
    "\n",
    "# а теперь посмотрим на преобразованные данные\n",
    "plt.plot(transformed_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем теперь из преобразованного временного ряда удалить тренд и\n",
    "визуализировать его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnottrend = []\n",
    "\n",
    "for i in range(1, len(transformed_data)):\n",
    "   pnottrend.append(transformed_data[i] - transformed_data[i-1])\n",
    "\n",
    "\n",
    "plt.plot(pnottrend) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалив тренд из преобразованного Боксом-Коксом ряда, попробуем опять проверить его на стационарность. Что-то изменилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "name = \"x после Кокса-Бокса\"\n",
    " \n",
    "ts = pnottrend\n",
    "\n",
    "print(f'Тест Дики-Фуллера ряда {name} :')\n",
    "dftest = adfuller(ts, autolag='AIC')\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "print(dfoutput)\n",
    "\n",
    "if dfoutput[\"p-value\"] < alpha:\n",
    "    print(f\"Значение p меньше {alpha * 100}%. Ряд стационарный.\")\n",
    "else:\n",
    "    print(f\"Значение p больше {alpha*100}%. Ряд не стационарный.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модели для предсказания значений временного ряда <a class=\"anchor\" id=\"predict\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первой моделью будет модель **AR**, или же autoregression - модель, которая использует связь между наблюдением и некоторым количеством предыдущих наблюдений.​\n",
    "\n",
    "Сделаем случайный ряд и затем поработаем с ним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR(1)\n",
    "\n",
    "N = 500\n",
    "\n",
    "ar1 = [1]\n",
    "\n",
    "for i in range(1, N):\n",
    "    ar1.append(0.76 * ar1[i-1] + np.random.random())\n",
    "\n",
    "plt.plot(ar1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим какие у него стандартное отклонение и среднее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"standart deviation = {np.std(ar1)}\\n mean = {np.mean(ar1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь обернем его в датафрейм и посмотрим его обычную и частичную автокорреляцию. Что можно сказать по поводу этого временного ряда, глядя на эти параметры?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.DataFrame(ar1)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 9))\n",
    "layout = (2, 2)\n",
    "ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "\n",
    "ts.plot(ax=ts_ax)\n",
    "ts_ax.set_title('Time Series Analysis Plots')\n",
    "smt.graphics.plot_acf(ts, lags=20, ax=acf_ax, alpha=0.5)\n",
    "smt.graphics.plot_pacf(ts, lags=10, ax=pacf_ax, alpha=0.5)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем ещё один случайный ряд, но уже и с отрицательными значениями коэффициента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR(1)\n",
    "\n",
    "N = 500\n",
    "\n",
    "ar2 = [1]\n",
    "\n",
    "for i in range(1, N):\n",
    "    ar2.append(- 0.76*ar2[i-1] + np.random.random())\n",
    "\n",
    "plt.plot(ar2)\n",
    "\n",
    "print(f\"standart deviation = {np.std(ar2)}\\n mean = {np.mean(ar2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что можно сказать по поводу этого ряда?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.DataFrame(ar2)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 9))\n",
    "layout = (2, 2)\n",
    "ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "\n",
    "ts.plot(ax=ts_ax)\n",
    "ts_ax.set_title('Time Series Analysis Plots')\n",
    "smt.graphics.plot_acf(ts, lags=20, ax=acf_ax, alpha=0.5)\n",
    "smt.graphics.plot_pacf(ts, lags=10, ax=pacf_ax, alpha=0.5)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь коэффициент >1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR(1)\n",
    "\n",
    "N = 500\n",
    "\n",
    "ar3 = [1]\n",
    "\n",
    "for i in range(1, N):\n",
    "    ar3.append(2 * ar3[i-1] + np.random.random())\n",
    "\n",
    "plt.plot(ar3)\n",
    "\n",
    "print(f\"standart deviation = {np.std(ar2)}\\n mean = {np.mean(ar2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ладно, пора возвращаться к прогнозированию. Следаем прогноз с помощью AR модели, предварительно поделив выборки на обучающую, валидационную и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Users/david/TimeSeries/data/Annual precipitation in inches entire great Lakes 19001986.csv', names=[\"n\",\"x\"], skiprows=1)\n",
    "\n",
    "\n",
    "df['t'] = df.index.values\n",
    "\n",
    "ln = len(df)\n",
    "\n",
    "# указываем 'объемы' выборок\n",
    "train_cutoff = int(round(ln*0.75, 0))\n",
    "validate_cutoff = int(round(ln*0.90,0))\n",
    "\n",
    "# делим выборки\n",
    "train_df = df[df['t'] <= train_cutoff]\n",
    "validate_df = df[(df['t'] > train_cutoff) & (df['t'] <= validate_cutoff)]\n",
    "forecast_df = df[df['t'] > validate_cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем поделенные выборки.\n",
    "\n",
    "* Обучающая выборка - синим цветом\n",
    "* Валидационная выборка - оранжевым цветом\n",
    "* Предсказываемая выборка - зеленым цветом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_df.t, train_df.x, label='Training data')\n",
    "plt.plot(validate_df.t, validate_df.x, label='Validate data')\n",
    "plt.plot(forecast_df.t, forecast_df.x, label='For prediction')\n",
    "plt.legend()\n",
    "plt.title('Airline passengers by month')\n",
    "plt.ylabel('Total passengers')\n",
    "plt.xlabel('Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем объект модели на основе данных временного ряда с 3 лагами\n",
    "mod = AutoReg(df.t, 3, old_names=False)\n",
    "# обучаем\n",
    "res = mod.fit()\n",
    "\n",
    "# выводим сводку информации об авторегрессионной модели\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# опять обучаем модель, но на этот раз указываем тип ковариационной оценки\n",
    "res = mod.fit(cov_type=\"HC0\")\n",
    "\n",
    "# смотрим, что изменилось\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжаем экспериментировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = ar_select_order(df.x, 13, old_names=False)\n",
    "sel.ar_lags\n",
    "res = sel.model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим, что он предсказал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = res.plot_predict(train_cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формируем предсказанные временные ряды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = res.predict(start=0, end=train_cutoff, dynamic=False)\n",
    "v_pred = res.predict(start=train_cutoff+1, end=(validate_cutoff), dynamic=False)\n",
    "f_pred = res.predict(start=validate_cutoff + 1, end=(forecast_df.t[len(df.t)-1]), dynamic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисовываем их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_df.t, train_df.x, label='Training data')\n",
    "plt.plot(validate_df.t, validate_df.x, label='Validate data')\n",
    "plt.plot(forecast_df.t, forecast_df.x, label='For prediction')\n",
    "plt.plot(validate_df.t, v_pred, label='Validate prediction ')\n",
    "plt.plot(forecast_df.t, f_pred, label='Forecast prediction')\n",
    "plt.plot(train_df.t, pred, label='Train prediction')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Airline x by time')\n",
    "plt.ylabel('Total x')\n",
    "plt.xlabel('time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MA\n",
    "\n",
    "df['t'] = df.index.values\n",
    "\n",
    "ln = len(df)\n",
    "\n",
    "# указываем 'объемы' выборок\n",
    "train_cutoff = int(round(ln*0.75, 0))\n",
    "validate_cutoff = int(round(ln*0.90,0))\n",
    "\n",
    "# делим выборки\n",
    "train_df = df[df['t'] <= train_cutoff]\n",
    "validate_df = df[(df['t'] > train_cutoff) & (df['t'] <= validate_cutoff)]\n",
    "forecast_df = df[df['t'] > validate_cutoff]\n",
    "\n",
    "plt.plot(train_df[\"t\"], train_df[\"x\"], label=\"original data\")\n",
    "plt.plot(train_df[\"t\"], train_df[\"x\"].rolling(10).mean(), label=\"MA\")\n",
    "plt.legend()\n",
    "plt.ylabel('Total x')\n",
    "plt.xlabel('time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики точности прогноза <a class=\"anchor\" id=\"metrics\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* R2- коэффициент детерминации     ​\n",
    "* MSE (RMSE) – mean squared error – среднеквадратичная ошибка​\n",
    "* MAE – mean absolute error – средняя абсолютная ошибка​\n",
    "* MAPE – mean absolute percentage error – средняя абсолютная ошибка в %​\n",
    "* SMAPE – symmetric mean absolute percentage error – симметричная средняя абсолютная ошибка в %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем метрики точности прогноза из библиотеки sklearn. Попробуй определить последнюю оставшуюся метрику **SMAPE** самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим значения ошибок модели AR, опираясь на предсказанные ею значения forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE:\", np.sqrt(mean_squared_error(forecast_df.x, f_pred)))\n",
    "print(\"MAPE:\", mean_absolute_percentage_error(forecast_df.x, f_pred))\n",
    "print(\"MAE:\", mean_absolute_error(forecast_df.x, f_pred))\n",
    "print(\"R2: \", r2_score(forecast_df.x, f_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
